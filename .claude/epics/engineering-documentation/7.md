---
name: Write development guides
status: completed
created: 2025-10-15T03:50:56Z
updated: 2025-10-19T17:18:37Z
completed: 2025-10-19T17:13:45Z
synced: 2025-10-19T17:18:37Z
github: https://github.com/lorenzotomasdiez/ArcAPI/issues/7
depends_on: [2, 3]
parallel: true
conflicts_with: []
---

# Task: Write Development Guides

## Description

Create comprehensive development documentation to enable new engineers to set up their local environment, understand coding standards, and follow the testing strategy. These guides are critical for developer onboarding and maintaining code quality.

Focus on **actionable, tested instructions** - every command should be copy-paste ready and verified to work.

**Critical for:** Developer onboarding, maintaining code quality, consistent development practices across team.

## Acceptance Criteria

- [ ] `docs/development/setup.md` completed with step-by-step local environment setup
- [ ] `docs/development/coding-standards.md` completed for TypeScript and Python
- [ ] `docs/development/testing-strategy.md` completed with unit/integration/E2E approach
- [ ] Setup guide tested by at least 2 engineers on different machines (Mac + Linux)
- [ ] Setup time <1 hour from README to running local dev server
- [ ] Coding standards include: naming conventions, file structure, linting rules, formatting
- [ ] Testing strategy specifies: coverage targets (80%+), frameworks, test organization

## Technical Details

### Document 1: Local Development Setup (`setup.md`)

**Goal**: New engineer goes from zero to running local dev environment in <1 hour

**Sections to Include:**

#### Prerequisites
- Node.js 20+ (specify exact version, use nvm)
- Python 3.11+ (for AI service, if applicable)
- PostgreSQL 15 (local or Docker)
- Redis 7 (local or Docker)
- Git
- VS Code (recommended) with extensions

**Commands (example):**
```bash
# Install Node.js with nvm
nvm install 20
nvm use 20

# Install pnpm (if using pnpm)
npm install -g pnpm

# Clone repository
git clone https://github.com/your-org/arca-api.git
cd arca-api
```

#### Environment Configuration
- Copy `.env.example` to `.env`
- Required environment variables:
  ```
  DATABASE_URL=postgresql://localhost:5432/arca_dev
  REDIS_URL=redis://localhost:6379
  ARCA_HOMOLOGACION_URL=https://wswhomo.afip.gov.ar/wsfev1/service.asmx
  OPENAI_API_KEY=sk-... (optional for local, mock AI service)
  ```

#### Database Setup
```bash
# Start PostgreSQL with Docker
docker run -d \
  --name arca-postgres \
  -e POSTGRES_DB=arca_dev \
  -e POSTGRES_PASSWORD=dev \
  -p 5432:5432 \
  postgres:15

# Run migrations
pnpm db:migrate

# Seed test data
pnpm db:seed
```

#### Start Development Servers
```bash
# Terminal 1: API server
pnpm dev:api

# Terminal 2: Dashboard (if applicable)
pnpm dev:dashboard

# Terminal 3: Redis
docker run -d --name arca-redis -p 6379:6379 redis:7

# Verify services running
curl http://localhost:3000/health
# Expected: {"status":"ok"}
```

#### Testing Setup
```bash
# Test ARCA homologación connection
pnpm test:arca-connection

# Run test suite
pnpm test
```

#### Troubleshooting
- PostgreSQL connection refused → check Docker container running
- Redis connection timeout → verify Redis container, check firewall
- Module not found → run `pnpm install`
- ARCA SOAP error → verify using homologación URL, not production

**Testing Certificates:**
- Provide link to ARCA homologación test certificates
- Include sample `.pfx` file for local testing (fake certificate, not real)

**Estimated Time**: 3 hours (write guide, test on 2 machines, refine)

### Document 2: Coding Standards (`coding-standards.md`)

**Goal**: Consistent code style across team, automated with linters

**TypeScript Standards:**

#### Naming Conventions
- Files: `kebab-case.ts` (e.g., `invoice-service.ts`)
- Classes: `PascalCase` (e.g., `InvoiceService`)
- Functions: `camelCase` (e.g., `createInvoice`)
- Constants: `UPPER_SNAKE_CASE` (e.g., `MAX_RETRIES`)
- Interfaces: `PascalCase` with `I` prefix (e.g., `IInvoiceData`) OR no prefix (depends on team decision)

#### File Structure
```
src/
├── controllers/     # HTTP request handlers
├── services/        # Business logic
├── repositories/    # Data access layer
├── models/          # Database models (Prisma, TypeORM, etc.)
├── types/           # TypeScript types and interfaces
├── utils/           # Utility functions
├── config/          # Configuration files
└── __tests__/       # Test files (mirror src structure)
```

#### Code Style (enforced by ESLint + Prettier)
- Indentation: 2 spaces
- Quotes: Single quotes for strings
- Semicolons: Always
- Max line length: 100 characters
- Arrow functions preferred over `function` keyword
- Async/await preferred over `.then()` chains

**Linting Configuration:**
```json
// .eslintrc.json
{
  "extends": ["airbnb-typescript/base", "prettier"],
  "rules": {
    "@typescript-eslint/explicit-function-return-type": "error",
    "no-console": "warn",
    "max-lines-per-function": ["warn", 50]
  }
}
```

**Python Standards (for AI Service):**

- Style guide: PEP 8 + Black formatter
- Naming: `snake_case` for functions, `PascalCase` for classes
- Type hints: Required for all functions
- Linting: `ruff` + `mypy`

**Estimated Time**: 2 hours

### Document 3: Testing Strategy (`testing-strategy.md`)

**Goal**: Comprehensive testing approach ensuring code quality

**Testing Pyramid:**

```
        /\
       /E2E\       (5% - Critical user journeys)
      /------\
     /Integ. \    (25% - Service interactions)
    /----------\
   /   Unit     \  (70% - Functions, classes)
  /--------------\
```

#### Unit Testing

**Framework:** Jest (TypeScript) or pytest (Python)

**Coverage Target:** 80% minimum, 90% preferred

**What to Test:**
- Business logic (services, utilities)
- Data transformations
- Validation functions
- Error handling

**Example:**
```typescript
// invoice-service.test.ts
describe('InvoiceService', () => {
  describe('calculateTotal', () => {
    it('should sum item prices with IVA', () => {
      const items = [
        { cantidad: 2, precio_unitario: 100, iva_porcentaje: 21 },
        { cantidad: 1, precio_unitario: 50, iva_porcentaje: 21 }
      ];
      const total = InvoiceService.calculateTotal(items);
      expect(total).toBe(302.5); // (200 + 50) * 1.21
    });

    it('should throw error for negative prices', () => {
      const items = [{ cantidad: 1, precio_unitario: -100, iva_porcentaje: 21 }];
      expect(() => InvoiceService.calculateTotal(items)).toThrow('Price cannot be negative');
    });
  });
});
```

**Commands:**
```bash
# Run unit tests
pnpm test:unit

# With coverage
pnpm test:unit --coverage
```

#### Integration Testing

**What to Test:**
- API endpoints (request → response)
- Database interactions
- External service mocks (ARCA, OpenAI)

**Framework:** Supertest (API testing) + Test database

**Example:**
```typescript
// invoices.integration.test.ts
describe('POST /invoices', () => {
  beforeAll(async () => {
    await setupTestDatabase();
  });

  it('should create invoice with valid data', async () => {
    const response = await request(app)
      .post('/invoices')
      .set('Authorization', `Bearer ${testApiKey}`)
      .send({
        mode: 'advanced',
        tipo_comprobante: 1,
        cliente: { /* ... */ },
        items: [ /* ... */ ]
      });

    expect(response.status).toBe(201);
    expect(response.body.cae).toBeDefined();
  });

  it('should return 401 without API key', async () => {
    const response = await request(app).post('/invoices').send({});
    expect(response.status).toBe(401);
  });
});
```

**Commands:**
```bash
# Run integration tests
pnpm test:integration
```

#### End-to-End Testing

**What to Test:**
- Critical user journeys (5-10 flows)
- Invoice creation (simple + advanced)
- Certificate upload
- Webhook delivery

**Framework:** Playwright or Cypress (if Dashboard exists)

**Strategy:**
- Run against local environment
- Mock ARCA API (use recorded responses)
- Test data cleanup after each run

**Estimated Time**: 2.5 hours

### Implementation Approach

1. **Start with setup guide** - most important, blocks onboarding
2. **Test setup guide** on 2 different machines (Mac + Linux, or Windows)
3. **Refine setup guide** based on issues found during testing
4. **Write coding standards** (copy team's existing practices or use Airbnb style guide)
5. **Define testing strategy** (specify frameworks, coverage targets, test structure)
6. **Add code examples** for each testing type
7. **Link guides together** (setup → coding standards → testing strategy)

### Files Affected

- Create: `docs/development/setup.md`
- Create: `docs/development/coding-standards.md`
- Create: `docs/development/testing-strategy.md`
- Update: `docs/development/README.md` (index of dev guides)
- Create: `.eslintrc.json`, `.prettierrc.json` (if not exists)
- Create: `jest.config.js` or `vitest.config.ts` (if not exists)

## Dependencies

**Depends On:**
- Task 001 (needs `development/` directory)
- Task 002 (references architecture decisions, e.g., database choice)

**Blocks:**
- Developer onboarding (can't start coding without setup guide)
- Code quality enforcement (coding standards needed for PR reviews)

**Can Run in Parallel With:**
- Task 003 (OpenAPI spec)
- Task 004 (service architecture)
- Task 005 (flows)

## Effort Estimate

- **Size**: M
- **Hours**: 10-12 hours over 1.5 days
- **Parallel**: true (different files from other tasks)
- **Breakdown**:
  - Setup guide writing: 2 hours
  - Setup guide testing (2 machines): 2 hours
  - Setup guide refinement: 1 hour
  - Coding standards: 2 hours
  - Testing strategy: 2.5 hours
  - Code examples and cross-linking: 1.5 hours

## Definition of Done

- [ ] Setup guide completed and tested on 2 different machines (Mac + Linux or Windows)
- [ ] Setup time measured: <1 hour from README to running dev server
- [ ] Coding standards documented for TypeScript (and Python if AI service in scope)
- [ ] Linting configuration files created (`.eslintrc.json`, `.prettierrc.json`)
- [ ] Testing strategy documented (unit, integration, E2E)
- [ ] Test framework configuration created (`jest.config.js` or equivalent)
- [ ] Code examples provided for each testing type
- [ ] Coverage targets specified (80% unit, 90% preferred)
- [ ] Troubleshooting section in setup guide covers common issues
- [ ] Documents linked from development README
- [ ] Peer review completed (2 engineers verify guides are clear and accurate)

## Notes

**Why this is critical:**
- **Onboarding speed**: Reduces new engineer ramp-up from days to hours
- **Code quality**: Automated linting prevents style bikeshedding
- **Test coverage**: Strategy ensures bugs caught before production
- **Team alignment**: Everyone follows same standards

**Testing the Setup Guide:**
- Must actually test on clean machines (not just your dev machine)
- Common gotcha: Missing prerequisite installation steps
- Use Docker for databases to avoid "works on my machine" issues

**Coding Standards Automation:**
- Lint on commit (use Husky + lint-staged)
- Fail CI if linting errors
- Auto-format on save (VS Code settings)

**Success Indicator:**
- New engineer sets up local environment in <1 hour (measured with timer)
- All PRs pass linting without manual fixes
- Test coverage dashboard shows >80% coverage

**Quick Wins:**
- Include VS Code workspace settings (`.vscode/settings.json`) for auto-format
- Provide Docker Compose file for one-command database setup
- Record video walkthrough of setup process (optional but helpful)

**References:**
- Airbnb JavaScript Style Guide: https://github.com/airbnb/javascript
- Jest Documentation: https://jestjs.io/
- Playwright Testing: https://playwright.dev/
